# Анализ и сравнение типов нейронных сетей для классификации изображений

Наиболее часто используемой для классификации архитектурой нейронных сетей являются сети прямого распространения, на входные нейроны которых подаются значения признаков классифицируемого объекта, а на выходе формируется метка класса. Обычно используются многослойные персептроны. В таких сетях элементы вектора признаков поступают на входные нейроны и распределяются на все нейроны первого скрытого слоя сети.

Недостатком такого подхода __для классификации изображений__ является плохая масштабируемость.

Изображение размером *n* x *n* пикселей можно представить как вектор из *n^2* элементов. Тогда каждый нейрона в первом скрытом слое сети будет связан с *n^2* нейронами входного слоя. С каждой связью ассоциируются некоторые коэффициенты (weight и bias), которые в последующем будут отпимизироваться с помощью метода обратного распространения ошибки. Таким образом, если в первом скрытом слое *k* нейронов, то уже имеется *kn^2* коэффициентов.

![Многослойный персептрон](..\example_pictures\multilayer_perceptron.png)

Размеры реальных изображений зачастую измеряются сотнями пикселей, что делает задачу классификации изображения с помощью многослойного персептрона крайне громоздкой вычислительно. 

Но это не единственный недостаток метода.

Подобная архитектура сети нечувствительна к пространственным зависимостям между пикселями, поэтому смещение изображение на несколько пикселей по вертикали или горизонтали может привести к неверной классификации.

Кроме того, такая архитектура не учитывает корреляцию между пикселями, хотя таким образом можно оптимизировать вычисления.

#### Поэтому для классификации изображений рациональнее использовать особые нейронные сети, называемые сверточными

Их преимущества заключаются  в том, что они
* уменьшают число входных нейронов
* менее чувствительны к смещениям изображения
* используются корреляцию, присутствующую между пикселями

### Структура сверточной нейронной сети (далее СНС)

СНС состоит из разных слоев: сверточных (convolutional), субдискретизирующих (sub-sampling, pooling) и слоев обычной нейронной сети (персептрона).

![Структура СНС](..\example_pictures\cnn_structure.png)

или

![Слои СНС](..\example_pictures\cnn_layers.png)

### Сверточный слой

Сверточный слой представляет из себя набор карт (feature map), у каждой карты есть ядро (еще называют фильтр).

Фильтр, который представляет собой обычную матрицу, последовательно накладывается на изображение. Область изображения, которая находится под фильтром, называется рецептивным полем, или полем восприятия. Скалярное произведение поля восприятия и фильтра дает число, которое попадает в карту признаков. Затем фильтр смещается, и каждое смещение постепенно заполняет карту признаков
(при этом фильтр будет пересекаться со своей предыдущей позицией).

В более привычной терминологии, фильтр — матрица весов. Получение карты признаков и есть свертка. 

Применение фильтров на рецептивном поле позволяет учитывать *корреляцию* находящихся рядом пикселей.

![Свертка](..\example_pictures\convolution.png)

Полученную карту признаков пропускают через функцию активации (часто ReLU). Эту карту можно повторно пропустить через новый фильтр и функцию активации. После свертки следующий этап — это подвыборка, или пулинг.

### Подвыборочный слой, пулинг

Цель этого слоя состоит в уменьшении размерности. Также этот слой отвечает за чувствительность модели к небольшим *смещениям* изображения. При пулинге (распространены max pooling или average pooling) карта признаков делится на области, при этом из каждой области выбирается максимальное (или среднее, в зависимости от метода) значение, которое попадает в пул.

![](..\example_pictures\max_pooling.png)

После чего пул может пройти через еще одну свертку и последующий пулинг, но в конце концов он должен прийти к полносвязному слою, которые применяются в стандартных нейронных сетях.

### Полносвязный слой

Это слой обычного многослойного персептрона. С помощью него моделируется сложная линейная функция, которая принимает на вход результаты последней подвыборки (пулинга), представленные в виде вектора. На выходе функция дает вектор, содержащих вероятности принадлежания изображения к каждому из классов. 

Важным этапом в построении полносвязной части СНС является выбор функции активации, т.к. у каждой есть свои достоинства и недостатки:

![Функции активации](..\example_pictures\activation_function.png)

# Источники

[Neural Networks Part 8: Image Classification with Convolutional Neural Networks by Josh Starmer](https://www.youtube.com/watch?v=HGwBXDKFk9I&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=13) 

[A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)

[Сверточная нейронная сеть, часть 1: структура, топология, функции активации и обучающее множество](https://habr.com/ru/post/348000/)

[Что такое сверточная нейронная сеть](https://habr.com/ru/post/309508/)